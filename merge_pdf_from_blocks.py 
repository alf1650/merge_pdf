#!/usr/bin/env python3
import os
import re
import json
import tempfile
from PyPDF2 import PdfReader, PdfWriter
from PIL import Image, ImageFile
import io

ImageFile.LOAD_TRUNCATED_IMAGES = True

def extract_block_from_filename(filename):
    match = re.match(r'^(\d{3})', filename)
    return int(match.group(1)) if match else None

def image_to_pdf_page(image_path, width_points, height_points, dpi=150):
    try:
        with Image.open(image_path) as img:
            if img.mode != 'RGB':
                img = img.convert('RGB')
            w_in = width_points / 72.0
            h_in = height_points / 72.0
            w_px = int(w_in * dpi)
            h_px = int(h_in * dpi)
            img.thumbnail((w_px, h_px), Image.Resampling.LANCZOS)
            canvas = Image.new('RGB', (w_px, h_px), (255, 255, 255))
            offset = ((w_px - img.width) // 2, (h_px - img.height) // 2)
            canvas.paste(img, offset)
            pdf_buffer = io.BytesIO()
            canvas.save(pdf_buffer, format='PDF', resolution=dpi)
            pdf_buffer.seek(0)
            reader = PdfReader(pdf_buffer)
            return reader.pages[0]
    except Exception as e:
        print(f"  ⚠️ Skipped image: {os.path.basename(image_path)} | {e}")
        return None

def split_pdf_to_pages(pdf_path, temp_dir):
    """Split PDF into individual pages."""
    reader = PdfReader(pdf_path)
    page_files = []
    for i in range(len(reader.pages)):
        writer = PdfWriter()
        writer.add_page(reader.pages[i])
        page_path = os.path.join(temp_dir, f"page_{i}.pdf")
        with open(page_path, "wb") as f:
            writer.write(f)
        page_files.append(page_path)
    return page_files

def process_single_page_with_images(page_pdf_path, blocks, image_dir, images_by_block):
    """Add images for given blocks to a single-page PDF."""
    reader = PdfReader(page_pdf_path)
    writer = PdfWriter()
    writer.add_page(reader.pages[0])  # Original page

    page = reader.pages[0]
    width_pts = float(page.mediabox.width)
    height_pts = float(page.mediabox.height)

    for block in blocks:
        if block in images_by_block:
            for img_path in images_by_block[block]:
                print(f"    ➕ Adding: {os.path.basename(img_path)}")
                pdf_page = image_to_pdf_page(img_path, width_pts, height_pts, dpi=150)
                if pdf_page:
                    writer.add_page(pdf_page)
    return writer

def main():
    input_pdf_dir = "/Users/alfredlim/Redpower/merge_pdf/input"
    image_dir = "/Users/alfredlim/Redpower/merge_pdf/images"
    json_dir = "/Users/alfredlim/Redpower/merge_pdf/ocr"
    output_dir = "/Users/alfredlim/Redpower/merge_pdf/output"
    os.makedirs(output_dir, exist_ok=True)

    pdf_files = [f for f in os.listdir(input_pdf_dir) if f.lower().endswith('.pdf')]
    if not pdf_files:
        print("❌ No PDFs found.")
        return

    # Build image index
    image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
    images_by_block = {}
    for img_file in image_files:
        img_path = os.path.join(image_dir, img_file)
        if os.path.getsize(img_path) == 0:
            print(f"⚠️ Skipping empty file: {img_file}")
            continue
        block = extract_block_from_filename(img_file)
        if block is not None:
            images_by_block.setdefault(block, []).append(img_path)
        else:
            print(f"⚠️ Skipping (no block): {img_file}")

    # Sort images within each block
    for block in images_by_block:
        images_by_block[block].sort()

    print(f"✅ Loaded {len(image_files)} images for {len(images_by_block)} blocks.")

    # Process each PDF
    for pdf_filename in pdf_files:
        base_name = os.path.splitext(pdf_filename)[0]
        json_path = os.path.join(json_dir, f"{base_name}_blocks.json")
        pdf_path = os.path.join(input_pdf_dir, pdf_filename)
        output_path = os.path.join(output_dir, f"{base_name}_WITH_IMAGES.pdf")

        if not os.path.isfile(json_path):
            print(f"⚠️ Skipping {pdf_filename}: JSON not found")
            continue

        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)

        with tempfile.TemporaryDirectory() as temp_dir:
            print(f"\n📄 Processing: {pdf_filename}")
            page_files = split_pdf_to_pages(pdf_path, temp_dir)
            print(f"   Split into {len(page_files)} pages.")

            # Process each page individually
            final_writer = PdfWriter()
            for i, page_pdf in enumerate(page_files):
                if i >= len(data["pages"]):
                    print(f"  ⚠️ Page {i+1}: no JSON data, skipping.")
                    continue

                page_info = data["pages"][i]
                blocks = page_info["clean_blocks"]
                print(f"  ➕ Page {i+1}: blocks {blocks}")

                # Process this single page with its images
                page_with_images = process_single_page_with_images(
                    page_pdf, blocks, image_dir, images_by_block
                )

                # Append all pages (original + images) to final PDF
                for p in page_with_images.pages:
                    final_writer.add_page(p)

            # Save final merged PDF
            with open(output_path, "wb") as f:
                final_writer.write(f)
            print(f"✅ Output saved: {output_path}")

    print(f"\n🎉 All done! Outputs in: {output_dir}")

if __name__ == "__main__":
    main()